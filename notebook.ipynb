{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import textwrap\n",
    "from skolegpt_instruct_dataset.translate import translate_with_deepl\n",
    "\n",
    "n_max = 5000000\n",
    "count_tokens_and_chars = True\n",
    "file_name = \"orca_sample_5M.json\"\n",
    "text_cols = [\"system_prompt\", \"question\", \"response\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df_pl = pl.read_parquet(\"orca_sample_5M.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    df = pd.read_json(file_name)\n",
    "except:\n",
    "\n",
    "    ds = load_dataset(\"Open-Orca/OpenOrca\", streaming=True, split=\"train\")\n",
    "    ds = ds.shuffle(seed=42)\n",
    "\n",
    "    examples = []\n",
    "    for example in tqdm(ds):\n",
    "        examples.append(example)\n",
    "        if len(examples) > n_max:\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame(examples)\n",
    "    df.to_json(file_name)\n",
    "\n",
    "df[\"source\"] = df[\"id\"].str.split(\".\").apply(lambda x: x[0])\n",
    "\n",
    "if count_tokens_and_chars:\n",
    "    # count tokens\n",
    "    num_tokens = 0\n",
    "    num_chars = 0\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    for col in text_cols:\n",
    "        num_tokens += df[col].apply(lambda x: len(encoding.encode(x))).sum()\n",
    "        num_chars += df[col].str.len().sum()\n",
    "        \n",
    "num_tokens_per_example = num_tokens/len(df)\n",
    "num_chars_per_example = num_chars/len(df)\n",
    "\n",
    "print(\"TOKENS:\")\n",
    "print(\"Number of tokens:\", num_tokens)\n",
    "print(\"Number of tokens per example:\", round(num_tokens_per_example, 2))\n",
    "print()\n",
    "\n",
    "print(\"CHARS:\")\n",
    "print(\"Number of chars:\", num_chars)\n",
    "print(\"Number of chars per example:\", round(num_chars_per_example,2))\n",
    "print()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepl_price_per_million_char = 21.86\n",
    "deepl_price_per_char = deepl_price_per_million_char / 1000000\n",
    "max_budget = 732.73 # 1465.46 \n",
    "\n",
    "max_budget/(num_tokens_per_example*deepl_price_per_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_example(df):\n",
    "    example = df.sample(n=1)\n",
    "    return example.to_dict(\"records\")[0]\n",
    "\n",
    "example = sample_example(df)\n",
    "example\n",
    "\n",
    "def print_example(example):\n",
    "    print(\"ID:\", example['id'])\n",
    "    print()\n",
    "    print(\"--- System Prompt ---\\n{input}\".format(input=textwrap.fill(example['system_prompt'])))\n",
    "    print()\n",
    "    print(\"--- Question ---\\n{input}\".format(input=textwrap.fill(example['question'])))\n",
    "    print()\n",
    "    print(\"--- Response ---\\n{input}\".format(input=textwrap.fill(example['response'])))\n",
    "\n",
    "print_example(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translate_with_deepl(\n",
    "    text=example[\"response\"],\n",
    "    target_lang=\"DA\"\n",
    ")\n",
    "\n",
    "print(textwrap.fill(translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.source.value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cot = df[df[\"source\"] == \"cot\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "df_stratified = pd.concat(\n",
    "    [\n",
    "        df.loc[df[\"source\"] == \"t0\"].sample(n_cot, random_state=seed),\n",
    "        df.loc[df[\"source\"] == \"flan\"].sample(n_cot, random_state=seed),\n",
    "        df.loc[df[\"source\"] == \"niv\"].sample(n_cot, random_state=seed),\n",
    "        df.loc[df[\"source\"] == \"cot\"],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_example(sample_example(df[df[\"source\"] == \"cot\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
