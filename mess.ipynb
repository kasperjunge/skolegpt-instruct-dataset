{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import pathlib\n",
    "import polars as pl\n",
    "from skolegpt_instruct_dataset.data import get_data\n",
    "from skolegpt_instruct_dataset.preprocess import preprocess_data\n",
    "from skolegpt_instruct_dataset.utils import sample_and_print_example, analyse_pre_and_postfixes\n",
    "from skolegpt_instruct_dataset.config import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_file = pathlib.Path(\"orca_sample.parquet\")\n",
    "cache_file_preprocessed = pathlib.Path(\"orca_sample_preprocessed.parquet\")\n",
    "use_cache = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>system_prompt</th><th>question</th><th>response</th><th>source</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;cot.47001&quot;</td><td>&quot;You are an AI …</td><td>&quot;Question: Whic…</td><td>&quot;Sure, I&#x27;d be h…</td><td>&quot;cot&quot;</td></tr><tr><td>&quot;t0.1981815&quot;</td><td>&quot;You are an AI …</td><td>&quot;Read the bio b…</td><td>&quot;- Instrument: …</td><td>&quot;t0&quot;</td></tr><tr><td>&quot;flan.1484600&quot;</td><td>&quot;You are an AI …</td><td>&quot;Determine if t…</td><td>&quot;The sentence &quot;…</td><td>&quot;flan&quot;</td></tr><tr><td>&quot;t0.750125&quot;</td><td>&quot;You are an AI …</td><td>&quot;Question: cats…</td><td>&quot;The correct an…</td><td>&quot;t0&quot;</td></tr><tr><td>&quot;t0.1336221&quot;</td><td>&quot;You are an AI …</td><td>&quot;Answer the fol…</td><td>&quot;This product r…</td><td>&quot;t0&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────┬─────────────────────┬──────────────────────────┬─────────────────────────┬────────┐\n",
       "│ id           ┆ system_prompt       ┆ question                 ┆ response                ┆ source │\n",
       "│ ---          ┆ ---                 ┆ ---                      ┆ ---                     ┆ ---    │\n",
       "│ str          ┆ str                 ┆ str                      ┆ str                     ┆ str    │\n",
       "╞══════════════╪═════════════════════╪══════════════════════════╪═════════════════════════╪════════╡\n",
       "│ cot.47001    ┆ You are an AI       ┆ Question: Which of the   ┆ Sure, I'd be happy to   ┆ cot    │\n",
       "│              ┆ assistant that hel… ┆ following…               ┆ help you w…             ┆        │\n",
       "│ t0.1981815   ┆ You are an AI       ┆ Read the bio below and   ┆ - Instrument: Trumpet   ┆ t0     │\n",
       "│              ┆ assistant that fol… ┆ try to gi…               ┆ - Years ac…             ┆        │\n",
       "│ flan.1484600 ┆ You are an AI       ┆ Determine if the         ┆ The sentence \"John's    ┆ flan   │\n",
       "│              ┆ assistant. You wil… ┆ sentence is tru…         ┆ manuscript …            ┆        │\n",
       "│ t0.750125    ┆ You are an AI       ┆ Question: cats have how  ┆ The correct answer is   ┆ t0     │\n",
       "│              ┆ assistant. User wi… ┆ many ape…                ┆ \"four legs…             ┆        │\n",
       "│ t0.1336221   ┆ You are an AI       ┆ Answer the following     ┆ This product review     ┆ t0     │\n",
       "│              ┆ assistant. Provide… ┆ question: T…             ┆ conveys a po…           ┆        │\n",
       "└──────────────┴─────────────────────┴──────────────────────────┴─────────────────────────┴────────┘"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "# get external data or load cached data\n",
    "if cache_file.is_file() & use_cache:\n",
    "    df_raw = pl.read_parquet(cache_file)\n",
    "else:\n",
    "    df_raw = get_data(n_max=config.n_max)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "if cache_file_preprocessed.is_file() & use_cache:\n",
    "    df= pl.read_parquet(cache_file_preprocessed)\n",
    "else:\n",
    "    df = preprocess_data(\n",
    "        df=df_raw, \n",
    "        n_total=config.n_total, \n",
    "        instruction_sources=config.instruction_sources,\n",
    "        common_postfixes=config.common_postfixes, \n",
    "        common_prefixes=config.common_prefixes, \n",
    "        seed=config.seed\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\n",
      "cot.45481\n",
      "\n",
      "SYSTEM PROMPT:\n",
      "\n",
      "You are an AI assistant that helps people find information. User will\n",
      "you give you a question. Your task is to answer as faithfully as you\n",
      "can. While answering think step-bystep and justify your answer.\n",
      "\n",
      "QUESTION:\n",
      "\n",
      "Premise: \"A man with black hair and gray pants is standing holding a\n",
      "helmet and looks very dirty.\" Hypothesis: \"A woman without a purse\n",
      "rides a gorilla.\" Do we know that the hypothesis entailed by the\n",
      "premise?. Le: OK, so how can I answer with some explanation?\n",
      "\n",
      "RESPONSE:\n",
      "\n",
      "Based on the given premise, we can conclude that a man with black hair\n",
      "and gray pants is standing holding a helmet and looks very dirty.\n",
      "However, there is no information provided in the premise that can lead\n",
      "us to the hypothesis that a woman without a purse rides a gorilla.\n",
      "Therefore, we cannot say that the hypothesis is entailed by the\n",
      "premise.  In logic, entailment means that the truth of one statement\n",
      "logically guarantees the truth of another statement. In this case,\n",
      "there is no logical connection between the premise and the hypothesis.\n",
      "The two statements are completely unrelated and there is no way to\n",
      "infer one from the other.  Therefore, we can say that the hypothesis\n",
      "is not entailed by the premise.\n"
     ]
    }
   ],
   "source": [
    "_ = sample_and_print_example(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87808\n",
      "ID\n",
      "cot.88876\n",
      "\n",
      "SYSTEM PROMPT:\n",
      "\n",
      "You are an AI assistant that helps people find information.\n",
      "\n",
      "QUESTION:\n",
      "\n",
      "Stream of consciousness rationale: Blue outfit is not a red outfit.\n",
      "Lounging on floor pillow is different to doing jumping jacks. The\n",
      "question and answer pair are described below.\n",
      "\n",
      "RESPONSE:\n",
      "\n",
      "Question: What is the difference between wearing a blue outfit and a\n",
      "red outfit?  Answer: Wearing a blue outfit is not the same as wearing\n",
      "a red outfit. They are two different colors and can create different\n",
      "moods or impressions.  Question: How is lounging on a floor pillow\n",
      "different from doing jumping jacks?  Answer: Lounging on a floor\n",
      "pillow is a relaxed and comfortable activity, while doing jumping\n",
      "jacks is a more active and energetic activity. They involve different\n",
      "levels of physical exertion and serve different purposes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>system_prompt</th><th>question</th><th>response</th><th>source</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;cot.88876&quot;</td><td>&quot;You are an AI …</td><td>&quot;Stream of cons…</td><td>&quot;Question: What…</td><td>&quot;cot&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 5)\n",
       "┌───────────┬─────────────────────────┬─────────────────────────┬─────────────────────────┬────────┐\n",
       "│ id        ┆ system_prompt           ┆ question                ┆ response                ┆ source │\n",
       "│ ---       ┆ ---                     ┆ ---                     ┆ ---                     ┆ ---    │\n",
       "│ str       ┆ str                     ┆ str                     ┆ str                     ┆ str    │\n",
       "╞═══════════╪═════════════════════════╪═════════════════════════╪═════════════════════════╪════════╡\n",
       "│ cot.88876 ┆ You are an AI assistant ┆ Stream of consciousness ┆ Question: What is the   ┆ cot    │\n",
       "│           ┆ that hel…               ┆ rational…               ┆ difference…             ┆        │\n",
       "└───────────┴─────────────────────────┴─────────────────────────┴─────────────────────────┴────────┘"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload\n",
    "from skolegpt_instruct_dataset.utils import return_filter_char_list\n",
    "def contains_characters(text, characters):\n",
    "    for char in characters:\n",
    "        if char in text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "df_filt = df.filter(~df[\"question\"].map_elements(lambda x: contains_characters(text=x, characters=return_filter_char_list())))\n",
    "df_filt = df_filt.filter(~df_filt[\"response\"].map_elements(lambda x: contains_characters(text=x, characters=return_filter_char_list())))\n",
    "\n",
    "print(len(df_filt))\n",
    "sample_and_print_example(df_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Regex pattern to match the different option formats\n",
    "option_patterns = [\n",
    "    r'(?i)\\b[A-D]\\)',  # Matches A), B), C), D) in a case-insensitive manner\n",
    "    r'(?i)\\b[1-4]\\)',  # Matches 1), 2), 3), 4) in a case-insensitive manner\n",
    "    r'(?i)\\b\\([A-D]\\)',  # Matches (A), (B), (C), (D) in a case-insensitive manner\n",
    "    r'(?i)\\b[A-D]\\.'  # Matches A., B., C., D. in a case-insensitive manner\n",
    "]\n",
    "combined_option_pattern = '|'.join(option_patterns)\n",
    "\n",
    "# Condition for filtering\n",
    "condition = (\n",
    "    (df[\"question\"].str.contains(\"Options:\") | df[\"question\"].str.contains(\"OPT:\")) |\n",
    "    df[\"question\"].str.contains(combined_option_pattern)\n",
    ")\n",
    "\n",
    "# Apply the filter\n",
    "df_filtered = df.filter(~condition)\n",
    "len(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "s = sample_and_print_example(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[\"source\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[\"question\"].item().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "analyse_pre_and_postfixes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO næste gang:\n",
    "# - Fjern multiple choice\n",
    "# - Fjern tekster med ikke-engelske chars\n",
    "# - Fjern flere dumme pre/postfixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improvements:\n",
    "# - Translate Removal: Consider false postives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
